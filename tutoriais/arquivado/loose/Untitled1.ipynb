{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9e46dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import pyproj\n",
    "from shapely import geometry\n",
    "\n",
    "import verde as vd\n",
    "import rioxarray as rio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "gdb = '/home/ggrl/geodatabase/'\n",
    "\n",
    "# LEVANTAMENTO 1089 # tie + flight_lines\n",
    "geof_1089 =pd.read_csv(gdb+'geof/g1089')\n",
    "\n",
    "\n",
    "#                                      DEFININDO FUNÇÕES PARA SCRIPT \n",
    "\n",
    "# Definindo Regions (W,E,S,N)\n",
    "def regions(gdf):\n",
    "    # Criando Region em coordenadas geograficas\n",
    "    bounds = gdf.bounds \n",
    "    gdf['region'] = \\\n",
    "    [(left,right,bottom,top) for left,right,bottom,top in zip(bounds['minx'],bounds['maxx'],\n",
    "                                                              bounds['miny'],bounds['maxy'])]\n",
    "\n",
    "    # Criando Region em coordenadas Projetadas    #gdf = gdf.set_crs(32723, allow_override=True)\n",
    "    gdf = gdf.to_crs(\"EPSG:32723\")\n",
    "    bounds = gdf.bounds \n",
    "    gdf['region_proj'] = \\\n",
    "    [(left,right,bottom,top) for left,right,bottom,top in zip(bounds['minx'],bounds['maxx'],\n",
    "                                                          bounds['miny'],bounds['maxy'])]\n",
    "    \n",
    "    return gdf\n",
    "        \n",
    "\n",
    "# Definindo nomes da malha a partir da articulação sistematica de folhas de cartas. Construindo uma lista e definindo como uma series.\n",
    "def nomeador_malha(gdf):\n",
    "    df = pd.DataFrame(gdf)\n",
    "    lista_grid = []\n",
    "    for index, row in df.iterrows():\n",
    "        row['id_folha'] = (nomeador_grid(row.region[0],row.region[1],\n",
    "                                         row.region[3],row.region[2],escala=5))\n",
    "        lista_grid.append(row.id_folha)\n",
    "\n",
    "    gdf['id_folha'] = lista_grid\n",
    "\n",
    "# Selecionador de Região\n",
    "def select_area(escala,id):\n",
    "    malha_cartog = importar('malha_cartog_'+escala+'_wgs84')\n",
    "    malha_cartog_gdf_select = malha_cartog[malha_cartog['id_folha'].str.contains(id)]       # '.contains' não é ideal.\n",
    "    malha_cartog_gdf_select = regions(malha_cartog_gdf_select)    \n",
    "    \n",
    "    return(malha_cartog_gdf_select)\n",
    "\n",
    "# Importador de Litologias por escala\n",
    "def importar(camada, mapa=False):\n",
    "    lito =  gpd.read_file(gdb+'database.gpkg',\n",
    "                        driver= 'GPKG',\n",
    "                        layer= camada)\n",
    "    if mapa:\n",
    "        folha = lito[lito.MAPA == 'Carta geológica da folha '+mapa]\n",
    "        return(folha)\n",
    "    else:\n",
    "        return(lito)\n",
    "    \n",
    "# Listando regiões das folhas cartográficas\n",
    "def cartas(escala,id):\n",
    "    malha_cartog_gdf_select = select_area(escala,id)\n",
    "    \n",
    "    # Apenas uma folha de carta\n",
    "    if (malha_cartog_gdf_select.shape[0]) > 1:\n",
    "        print(f\"# Foram selecionadas {len(malha_cartog_gdf_select)} folhas cartográfica em escala de {escala} selecionadas: {list(malha_cartog_gdf_select.index)}\")\n",
    "        \n",
    "        # Criando dicionário de cartas\n",
    "        malha_cartog_gdf_select.set_index('id_folha',inplace=True)\n",
    "        malha_cartog_gdf_select.drop(columns=['geometry'],inplace=True)\n",
    "        dic_cartas = malha_cartog_gdf_select.to_dict()\n",
    "        \n",
    "        \n",
    "    # Mais de uma folha de carta\n",
    "    if len(malha_cartog_gdf_select) == 1:\n",
    "        print(f\"# Foi selecionada {len(malha_cartog_gdf_select)} folha cartográfica em escala de {escala} selecionada: {list(malha_cartog_gdf_select.index)}\")\n",
    "       \n",
    "        # Criando dicionário de cartas\n",
    "        malha_cartog_gdf_select.set_index('id_folha',inplace=True)\n",
    "        malha_cartog_gdf_select.drop(columns=['geometry'],inplace=True)\n",
    "        dic_cartas = malha_cartog_gdf_select.to_dict()\n",
    "    \n",
    "    return malha_cartog_gdf_select ,dic_cartas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                                      DEFININDO FUNÇÃO DE SCRIPT    \n",
    "def interpolar(escala,id,geof,degree=2,spacing=499,psize=100,n_splits=False,save=False,describe_data=True,nome='Rio Paraim',crs__='proj'):\n",
    "    # Listando Canais de Interpolação\n",
    "    lista_canal=['CTCOR','eU','eth','MDT','KPERC']\n",
    "    \n",
    "    # Listando regiões das folhas cartográficas\n",
    "    malha_cartog_gdf_select, dic_cartas = cartas(escala,id)\n",
    "                    \n",
    "    # Listando colunas do dado aerogeofísico\n",
    "    print(f\"Lista de atributos:  {list(geof.columns)}\")\n",
    "    \n",
    "    # Dicionário de dados interpolados\n",
    "    grids = {lista_canal[0]:(),lista_canal[1]:(),lista_canal[2]:(),lista_canal[3]:(), lista_canal[4]:()}\n",
    "    \n",
    "    # Dicionário validação cruzada\n",
    "    scores = {lista_canal[0]:(),lista_canal[1]:(),lista_canal[2]:(), lista_canal[3]:(), lista_canal[4]:()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Iterando entre itens da lista de folhas cartográficas\n",
    "    for n in trange(1):\n",
    "        for index, row in malha_cartog_gdf_select.iterrows():\n",
    "            #print(f\"index: {index} e row: {row}\")\n",
    "            print(f\"# -- Início da iteração da folha: {index} #\")\n",
    "            if crs__ == 'proj':\n",
    "                data= geof[vd.inside((geof.X, geof.Y), region = row.region_proj)]\n",
    "                coordinates = (data.X.values, data.Y.values)\n",
    "            else:\n",
    "                data= geof[vd.inside((geof.LONGITUDE, geof.LATITUDE), region = row.region)]\n",
    "                coordinates = (data.X.values, data.Y.values)\n",
    "                \n",
    "            #print('# Distribuição')\n",
    "            #print(f\"{data['CTCOR'].describe(percentiles = [0.02, 0.25, 0.50, 0.75, 0.995])}\")\n",
    "            #print('# Distribuição')\n",
    "            #print(f\"{data['eU'].describe(percentiles = [0.02, 0.25, 0.50, 0.75, 0.995])}\")\n",
    "\n",
    "            \n",
    "            if data.empty or len(data) < 1000:  # if data dont have values pass to next step\n",
    "                print('não há dados aerogofísicos para folha cartográfica de id: '+index)\n",
    "                print(f\"A folha possui:  {len(data)} pontos coletados\")\n",
    "\n",
    "            else:\n",
    "                print(f\"com {len(data)} pontos de contagens radiométricas coletados\")\n",
    "                print(f\"# -- Recortando dados da folha: {index} #\")\n",
    "                # Iterando entre os canais de interpolação\n",
    "                # Definindo encadeamento de processsos para interpolação\n",
    "                chain = vd.Chain([\n",
    "                                ('trend', vd.Trend(degree=degree)),\n",
    "                                ('reduce', vd.BlockReduce(np.median, spacing=spacing)),\n",
    "                                ('spline', vd.Spline())\n",
    "                            ])\n",
    "                print(\"pipeline\")\n",
    "                print(f\" {chain} \")\n",
    "                \n",
    "                for n in trange(1):\n",
    "                    print(f\"# -- Inicio da interpolação -- # \")\n",
    "                    print('fit: ')\n",
    "                    \n",
    "                    for i in lista_canal:\n",
    "                        chain.fit(coordinates, data[i])\n",
    "                        print(i)\n",
    "                        \n",
    "\n",
    "                        # Griding the predicted data.  \n",
    "                        grid = chain.grid(spacing=psize, data_names=[i],pixel_register=True)\n",
    "                        grids[i] = vd.distance_mask(coordinates, maxdist=spacing, grid= grid)\n",
    "                        \n",
    "                        \n",
    "                        # Processo de validação cruzada da biblioteca verde\n",
    "                        if n_splits:\n",
    "                            cv     = vd.BlockKFold(spacing=spacing,\n",
    "                                        n_splits=n_splits,\n",
    "                                        shuffle=True)\n",
    "\n",
    "                            scores[i] = vd.cross_val_score(chain,\n",
    "                                                    coordinates,\n",
    "                                                    data[i],\n",
    "                                                    cv=cv)\n",
    "                            \n",
    "\n",
    "                        \n",
    "                        # Salvar os dados interpolados em formato .tif\n",
    "                        if save:\n",
    "                            print('salvando '+index+' '+i)\n",
    "                            #grids[i].to_netcdf(gdb+'/grids/geof_3022_'+str(psize)+'m_'+i+'_'+row.id_folha+'.nc')\n",
    "                            tif_ = grids[i].rename(easting = 'x',northing='y')\n",
    "                            tif_.rio.to_raster(gdb+'grids/geof_'+str(save)+'_'+str(psize)+'m_'+i+'_'+row.id_folha+'.tif')\n",
    "                        \n",
    "                print(f\"# -- Fim da interpolação -- # {index}'\")\n",
    "                \n",
    "                \n",
    "                # Adicionando grids ao dicionario\n",
    "                print(f\"# Adicionando dicionário de grids com {len(grids)} canais ao dicionário de cartas\")\n",
    "                \n",
    "                dic_cartas['grids']= index\n",
    "                \n",
    "                # Adicionando scores ao dicionario\n",
    "                dic_cartas['scores'] = scores\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Descrição estatisica das contagens\n",
    "                if describe_data:\n",
    "                    dataframe = list()\n",
    "                    for i in lista_canal:\n",
    "                        df = grids[i].to_dataframe()\n",
    "                        dataframe.append(df[i])\n",
    "\n",
    "                    geof_grids = pd.concat(dataframe,axis=1, join='inner')\n",
    "                    geof_grids.reset_index(inplace=True)\n",
    "\n",
    "                    geof_grids['geometry'] =\\\n",
    "                         [geometry.Point(x,y) for x, y in zip(geof_grids['easting'], geof_grids['northing'])]\n",
    "\n",
    "                    print('Ajustando crs')\n",
    "\n",
    "                    if crs__=='proj':\n",
    "                        gdf = gpd.GeoDataFrame(geof_grids,crs=32723)\n",
    "                        gdf = gdf.set_crs(32723, allow_override=True)\n",
    "                        gdf = gdf.to_crs(\"EPSG:32723\")\n",
    "                        print(f\" geof: {gdf.crs}\")\n",
    "                    else:\n",
    "                        gdf = gpd.GeoDataFrame(geof_grids,crs=32723)\n",
    "                        gdf = gdf.set_crs(32723, allow_override=True)\n",
    "                        gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "                        print(f\" geof: {gdf.crs}\")\n",
    "\n",
    "                        \n",
    "                    #litologia=importar(lito,\"Rio de Janeiro\")\n",
    "                    litologia = importar('l_100k',nome)\n",
    "                    litologia.reset_index(inplace=True)\n",
    "                    if crs__=='proj':\n",
    "                        litologia = litologia.set_crs(32723, allow_override=True)\n",
    "                        litologia = litologia.to_crs(\"EPSG:32723\")\n",
    "                        print(f\" lito: {litologia.crs}\")\n",
    "                    else:\n",
    "                        litologia = litologia.set_crs(4326, allow_override=True)\n",
    "                        litologia = litologia.to_crs(\"EPSG:4326\")\n",
    "                        print(f\" lito: {litologia.crs}\")\n",
    "                        \n",
    "                    print(f\"# Listando de siglas de unidades litológicas do mapa {litologia['MAPA'].unique()}:       {list(litologia['SIGLA'].unique())} \") \n",
    "\n",
    "                    print(f\"# Calculando geometria mais próxima para cada um dos {len(geof_grids)} pixels da folha {index}\")\n",
    "\n",
    "\n",
    "                    geof_grids['closest_unid'] = gdf['geometry'].apply(lambda x: litologia['SIGLA'].iloc[litologia.distance(x).idxmin()])\n",
    "\n",
    "                    print(f\"# siglas de unidades litológicas presentes na folha de id {index}:    {list(geof_grids['closest_unid'].unique())}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    #print('# Distribuição')\n",
    "                    #print(f\"{geof_grids['CTCOR'].describe(percentiles = [0.02, 0.25, 0.50, 0.75, 0.995])}\")\n",
    "\n",
    "                    #print('# Distribuição')\n",
    "                    #print(f\"{geof_grids['eU'].describe(percentiles = [0.02, 0.25, 0.50, 0.75, 0.995])}\")\n",
    "                \n",
    "                print(f\"#{index}'# -- Fim da iteração -- #'\")\n",
    "                print('__________________________________________')\n",
    "    \n",
    "    return dic_cartas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60bbd7eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Foram selecionadas 4 folhas cartográfica em escala de 25k selecionadas: [11880, 11881, 11895, 11896]\n",
      "Lista de atributos:  ['X', 'Y', 'MDT', 'KPERC', 'eU', 'eth', 'CTCOR', 'LONGITUDE', 'LATITUDE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/geologist_bot/lib/python3.7/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f532de828b1e47a4b476491d566bc5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -- Início da iteração da folha: SC23_Z_A_IV_2_SW #\n",
      "com 4890 pontos de contagens radiométricas coletados\n",
      "# -- Recortando dados da folha: SC23_Z_A_IV_2_SW #\n",
      "pipeline\n",
      " Chain(steps=[('trend', Trend(degree=2)),\n",
      "             ('reduce',\n",
      "              BlockReduce(reduction=<function median at 0x7f793feff680>,\n",
      "                          spacing=499)),\n",
      "             ('spline', Spline())]) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc19828935043479af78e48482d7326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -- Inicio da interpolação -- # \n",
      "fit: \n",
      "CTCOR\n",
      "eU\n",
      "eth\n",
      "MDT\n",
      "KPERC\n",
      "# -- Fim da interpolação -- # SC23_Z_A_IV_2_SW'\n",
      "# Adicionando dicionário de grids com 5 canais ao dicionário de cartas\n",
      "#SC23_Z_A_IV_2_SW'# -- Fim da iteração -- #'\n",
      "__________________________________________\n",
      "# -- Início da iteração da folha: SC23_Z_A_IV_2_NW #\n",
      "com 5062 pontos de contagens radiométricas coletados\n",
      "# -- Recortando dados da folha: SC23_Z_A_IV_2_NW #\n",
      "pipeline\n",
      " Chain(steps=[('trend', Trend(degree=2)),\n",
      "             ('reduce',\n",
      "              BlockReduce(reduction=<function median at 0x7f793feff680>,\n",
      "                          spacing=499)),\n",
      "             ('spline', Spline())]) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdcc3a563ae45ce95dee7a487edc6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -- Inicio da interpolação -- # \n",
      "fit: \n",
      "CTCOR\n",
      "eU\n",
      "eth\n",
      "MDT\n",
      "KPERC\n",
      "# -- Fim da interpolação -- # SC23_Z_A_IV_2_NW'\n",
      "# Adicionando dicionário de grids com 5 canais ao dicionário de cartas\n",
      "#SC23_Z_A_IV_2_NW'# -- Fim da iteração -- #'\n",
      "__________________________________________\n",
      "# -- Início da iteração da folha: SC23_Z_A_IV_2_SE #\n",
      "com 5054 pontos de contagens radiométricas coletados\n",
      "# -- Recortando dados da folha: SC23_Z_A_IV_2_SE #\n",
      "pipeline\n",
      " Chain(steps=[('trend', Trend(degree=2)),\n",
      "             ('reduce',\n",
      "              BlockReduce(reduction=<function median at 0x7f793feff680>,\n",
      "                          spacing=499)),\n",
      "             ('spline', Spline())]) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa65afd2f1804eaea4d28a4606967e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -- Inicio da interpolação -- # \n",
      "fit: \n",
      "CTCOR\n",
      "eU\n",
      "eth\n",
      "MDT\n",
      "KPERC\n",
      "# -- Fim da interpolação -- # SC23_Z_A_IV_2_SE'\n",
      "# Adicionando dicionário de grids com 5 canais ao dicionário de cartas\n",
      "#SC23_Z_A_IV_2_SE'# -- Fim da iteração -- #'\n",
      "__________________________________________\n",
      "# -- Início da iteração da folha: SC23_Z_A_IV_2_NE #\n",
      "com 5251 pontos de contagens radiométricas coletados\n",
      "# -- Recortando dados da folha: SC23_Z_A_IV_2_NE #\n",
      "pipeline\n",
      " Chain(steps=[('trend', Trend(degree=2)),\n",
      "             ('reduce',\n",
      "              BlockReduce(reduction=<function median at 0x7f793feff680>,\n",
      "                          spacing=499)),\n",
      "             ('spline', Spline())]) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fa41577bd0440484513c0731077306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -- Inicio da interpolação -- # \n",
      "fit: \n",
      "CTCOR\n",
      "eU\n",
      "eth\n",
      "MDT\n",
      "KPERC\n",
      "# -- Fim da interpolação -- # SC23_Z_A_IV_2_NE'\n",
      "# Adicionando dicionário de grids com 5 canais ao dicionário de cartas\n",
      "#SC23_Z_A_IV_2_NE'# -- Fim da iteração -- #'\n",
      "__________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Levantamento 1089  - Folha SC23_Z_A_IV_2\n",
    "dic_cartas =  interpolar('25k','SC23_Z_A_IV_2',geof_1089,crs__='geografica',degree=2,spacing=499,psize=100,describe_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4717d764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dic_cartas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8b9f169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_cartas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d9ab194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_cartas['grids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61776a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
