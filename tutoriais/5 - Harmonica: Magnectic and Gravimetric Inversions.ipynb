{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import my_funcs as f\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import harmonica as hm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import tqdm \n",
    "from tqdm.notebook import trange"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%matplotlib widget"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import pyproj\n",
    "from shapely import geometry\n",
    "\n",
    "import verde as vd\n",
    "import rioxarray as rio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "####################################### LEMBRAR DE PEDIR AJUDA\n",
    "import tqdm \n",
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "# DEFININDO CAMINHO PARA A BASE DE DADOS\n",
    "gdb = '/home/ggrl/geodatabase/'\n",
    "\n",
    "\n",
    "# ---------------------------------------- DEFININDO FUNÇÕES PARA SCRIPT ---------------------------------------#\n",
    "\n",
    "# IMPORTADOR DE DADOS AEROGEOFISICOS\n",
    "def importar_geof(raw_data):\n",
    "    geof_dataframe = pd.read_csv(gdb+'/geof/'+str(raw_data))\n",
    "    return geof_dataframe\n",
    "\n",
    "\n",
    "# IMPORTADOR DE LITOLOGIAS POR ESCALA --------------------------------------------------------------------------#\n",
    "def importar(camada, mapa=False):\n",
    "    lito =  gpd.read_file(gdb+'database.gpkg',\n",
    "                        driver= 'GPKG',\n",
    "                        layer= camada)\n",
    "    if mapa:\n",
    "        folha = lito[lito.MAPA == 'Carta geológica da folha '+mapa]\n",
    "        return(folha)\n",
    "    else:\n",
    "        return(lito)\n",
    "\n",
    "    \n",
    "# DEFININDO LIMITES DE CADA FOLHA CARTOGRÁFICA -----------------------------------------------------------------#\n",
    "def regions(gdf):\n",
    "    # CRIANDO COLUNA REGION EM COORDENADAS GEOGRÁFICAS\n",
    "    bounds = gdf.bounds\n",
    "    #print(bounds[:1])\n",
    "\n",
    "    gdf['region'] = \\\n",
    "    [(left,right,bottom,top) for left,right,bottom,top in zip(bounds['minx'],bounds['maxx'],\n",
    "                                                              bounds['miny'],bounds['maxy'])]\n",
    "\n",
    "    # CRIANDOCOLUNA REGIONS EM COORDENADAS PROJETADAS\n",
    "    gdf = gdf.to_crs(\"EPSG:32723\")\n",
    "    #print(f\"{gdf.crs}\")\n",
    "    \n",
    "    bounds = gdf.bounds\n",
    "    #print(bounds[:1])\n",
    "    \n",
    "    gdf['region_proj'] = \\\n",
    "    [(left,right,bottom,top) for left,right,bottom,top in zip(bounds['minx'],bounds['maxx'],\n",
    "                                                          bounds['miny'],bounds['maxy'])]\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# Nomeador de Grids ------------------------------------------------------------------------------------------#\n",
    "def nomeador_grid(left,right,top,bottom,escala=5):\n",
    "    e1kk=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "    e500k=[['V','Y'],['X','Z']]\n",
    "    e250k=[['A','C'],['B','D']]\n",
    "    e100k=[['I','IV'],['II','V'],['III','VI']]\n",
    "    e50k=[['1','3'],['2','4']]\n",
    "    e25k=[['NW','SW'],['NE','SE']]\n",
    "\n",
    "    if left>right:\n",
    "        print('Oeste deve ser menor que leste')\n",
    "    if top<bottom:\n",
    "        print('Norte deve ser maior que Sul')\n",
    "    \n",
    "    else:\n",
    "        id_folha=''\n",
    "        if top<=0:\n",
    "            id_folha+='S'\n",
    "            north=False\n",
    "            index=math.floor(-top/4)\n",
    "        else:\n",
    "            id_folha+='N'\n",
    "            north=True\n",
    "            index=math.floor(bottom/4)\n",
    "        \n",
    "        numero=math.ceil((180+right)/6)\n",
    "        id_folha+=e1kk[index]+str(numero)\n",
    "\n",
    "        lat_gap=abs(top-bottom)\n",
    "        #p500k-----------------------\n",
    "        if (lat_gap<=2) & (escala>=1):\n",
    "            LO=math.ceil(right/3)%2==0\n",
    "            NS=math.ceil(top/2)%2!=north\n",
    "            id_folha+='_'+e500k[LO][NS]\n",
    "        #p250k-----------------------\n",
    "        if (lat_gap<=1) & (escala>=2):\n",
    "            LO=math.ceil(right/1.5)%2==0\n",
    "            NS=math.ceil(top)%2!=north\n",
    "            id_folha+='_'+e250k[LO][NS]\n",
    "        #p100k-----------------------\n",
    "        if (lat_gap<=0.5) & (escala>=3):\n",
    "            LO=(math.ceil(right/0.5)%3)-1\n",
    "            NS=math.ceil(top/0.5)%2!=north\n",
    "            id_folha+='_'+e100k[LO][NS]\n",
    "        #p50k------------------------\n",
    "        if (lat_gap<=0.25) & (escala>=4):\n",
    "            LO=math.ceil(right/0.25)%2==0\n",
    "            NS=math.ceil(top/0.25)%2!=north\n",
    "            id_folha+='_'+e50k[LO][NS]\n",
    "        #p25k------------------------\n",
    "        if (lat_gap<=0.125) & (escala>=5):\n",
    "            LO=math.ceil(right/0.125)%2==0\n",
    "            NS=math.ceil(top/0.125)%2!=north\n",
    "            id_folha+='_'+e25k[LO][NS]\n",
    "        return id_folha\n",
    "\n",
    "\n",
    "# DEFININDO NOMES DA MALHA A PARTIR DA ARTICULA~AO SISTEMÁTICA DE FOLHAS DE CARTAS. \n",
    "# CONSTURINDO UMA LISTA E DEFININDO COMO UMA SERIES (OBJETO DO PANDAS).\n",
    "def nomeador_malha(gdf):\n",
    "    df = pd.DataFrame(gdf)\n",
    "    lista_malha = []\n",
    "    for index, row in df.iterrows():\n",
    "        row['id_folha'] = (nomeador_grid(row.region[0],row.region[1],\n",
    "                                         row.region[3],row.region[2],escala=5))\n",
    "        lista_malha.append(row.id_folha)\n",
    "\n",
    "    gdf['id_folha'] = lista_malha\n",
    "\n",
    "\n",
    "# SELECIONADOR DE REGIÃO  ------------------------------------------------------------------------------------------#\n",
    "def select_area(escala,id):\n",
    "    malha_cartog = importar('malha_cartog_'+escala+'_wgs84')\n",
    "    malha_cartog_gdf_select = malha_cartog[malha_cartog['id_folha'].str.contains(id)]       # '.contains' não é ideal.\n",
    "    malha_cartog_gdf_select = regions(malha_cartog_gdf_select)    \n",
    "    \n",
    "    return(malha_cartog_gdf_select)\n",
    "\n",
    "# LISTANDO REGIÕES DE CADA FOLHA DE CARTAS DA MALHA CARTOGRÁFICA \\ ['REGEION'] = ['ID_FOLHA'] REDUNDANCIA\n",
    "def cartas(escala,id):\n",
    "    # SELECIONANDO AREA DE ESTUDO\n",
    "    if escala and id:\n",
    "        print('# --- Iniciando seleção de área de estudo')\n",
    "        malha_cartog_gdf_select = select_area(escala,id)\n",
    "        #print(\"Indexando a coluna 'id_folha'\")\n",
    "        malha_cartog_gdf_select.set_index('id_folha',inplace=True)\n",
    "        print(malha_cartog_gdf_select.index)\n",
    "\n",
    "   \n",
    "    # CRIANDO UM DICIONÁRIO DE CARTAS\n",
    "    #print(f\"Retirada da coluna 'geometry'\")\n",
    "    malha_cartog_df_select = malha_cartog_gdf_select.drop(columns=['geometry'])\n",
    "    malha_cartog_df_select['raw_data'] =''\n",
    "    malha_cartog_df_select['interpolado'] =''\n",
    "    malha_cartog_df_select['scores'] =''\n",
    "    malha_cartog_df_select['lito_geof'] =''\n",
    "    malha_cartog_df_select['mean_score'] =''\n",
    "    print(\"Gerando dicionário com o index\")\n",
    "    dic_cartas = malha_cartog_df_select.to_dict()\n",
    "    print(dic_cartas.keys())\n",
    "    #print(dic_cartas)\n",
    "    \n",
    "    # APENAS UMA FOLHA DE CARTA SELECIONADA\n",
    "    if len(dic_cartas['raw_data']) > 1:\n",
    "        print(f\"{len(dic_cartas['raw_data'])} folhas cartográfica selecionadas\")\n",
    "        print(\"\")\n",
    "\n",
    "    # MAIS DE UMA FOLHA DE CARTA SELECIONADA\n",
    "    if len(dic_cartas['raw_data']) == 1:\n",
    "        print(f\"{len(dic_cartas['raw_data'])} folha cartográfica selecionada\")\n",
    "        print(\"\")\n",
    "    return malha_cartog_gdf_select, dic_cartas\n",
    "\n",
    "\n",
    "# LISTANDO ATRIBUTOS GEOFÍSICOS E ATRIBUTOS GEOGRÁFICOS\n",
    "def list_atributos(geof):\n",
    "    atributos_geof = list(geof.columns)\n",
    "    lista_atributo_geof=[]\n",
    "    lista_atributo_geog=[]\n",
    "    lista_atributo_proj=[]\n",
    "\n",
    "    for atributo in atributos_geof:\n",
    "        if atributo == 'LATITUDE':\n",
    "            lista_atributo_geog.append(atributo)\n",
    "        elif atributo == 'LONGITUDE':\n",
    "            lista_atributo_geog.append(atributo)\n",
    "        elif atributo == 'LONG':\n",
    "            lista_atributo_geog.append(atributo)\n",
    "        elif atributo == 'LAT':\n",
    "            lista_atributo_geog.append(atributo) \n",
    "        elif atributo == 'X':\n",
    "            lista_atributo_proj.append(atributo)\n",
    "        elif atributo == 'Y':\n",
    "            lista_atributo_proj.append(atributo)\n",
    "        elif atributo == 'UTME':\n",
    "            lista_atributo_proj.append(atributo)\n",
    "        elif atributo == 'UTMN':\n",
    "            lista_atributo_proj.append(atributo)\n",
    "        else:\n",
    "            lista_atributo_geof.append(atributo)\n",
    "    codigo=str(geof)        \n",
    "    print(f\"# --- # Listagem de dados do aerolevantamento:  \")\n",
    "    print(f\"Lista de atributos geofísicos = {lista_atributo_geof}\")\n",
    "    print(f\"lista de atributos geograficos = {lista_atributo_geog}\")\n",
    "    print(f\"lista de atributos projetados = {lista_atributo_proj}\")\n",
    "    return lista_atributo_geof, lista_atributo_geog, lista_atributo_proj\n",
    "\n",
    "\n",
    "# DESCRIÇÃO DOS DADOS AEROGEOFÍSICOS\n",
    "def descricao(geof):            \n",
    "    lista_atributo_geof,lista_atributo_geog,lista_atributo_proj = list_atributos(geof)  # USANDO FUNCAO DEFINIDA ACIMA PARA CATEGORIZAR METADADO\n",
    "    \n",
    "    datadict = pd.DataFrame(geof.dtypes)\n",
    "    datadict[\"Valores Faltantes\"] = geof.isnull().sum()\n",
    "    datadict[\"Valores Únicos\"] = geof.nunique()\n",
    "    datadict[\"Amostragem\"] = geof.count()\n",
    "    datadict = datadict.rename(columns = {0 : 'dType'})\n",
    "\n",
    "    lista_negativo=[]\n",
    "    for i in lista_atributo_geof:\n",
    "        lista_negativo.append(geof.query(i+' < 0')[i].count())\n",
    "\n",
    "\n",
    "    geof_df = geof.drop(axis=0,columns=lista_atributo_geog)\n",
    "    geof_df.drop(axis=0,columns=lista_atributo_proj,inplace=True)\n",
    "\n",
    "    #datadict['Valores Negativos'] = lista_negativo\n",
    "\n",
    "    geof_df_describe = geof_df.describe(percentiles=[0.001,0.1,0.25,0.5,0.75,0.995])\n",
    "    \n",
    "    return datadict,lista_atributo_geof,lista_atributo_geog,lista_atributo_proj,geof_df_describe\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "# # --------------------- DEFININDO FUNÇÃO DE QUE CHAMARÁ AS FUNÇÕES ANTERIORES PROVOCANDO UM ENCADEAMENTO DE OPERAÇÕES -------------- \n",
    "def interpolar(escala,id,geof,\n",
    "               standard_verde=None,psize=None,spacing=None,degree=None,n_splits=None,\n",
    "               camada=None,nome=None,crs__='proj',describe=False):\n",
    "    # DEFININDO PADRÃO DE INTERPOLAÇÃO VERDE\n",
    "    if standard_verde:\n",
    "        save=None\n",
    "        degree=1\n",
    "        spacing=499\n",
    "        psize= 100\n",
    "    else:\n",
    "        save=None\n",
    "        degree=degree\n",
    "        spacing=spacing\n",
    "        psize=psize\n",
    "                \n",
    "    # LISTANDO REGIOES DAS FOLHAS DE CARTAS\n",
    "    malha_cartog_gdf_select, dic_cartas = cartas(escala,id)\n",
    "        \n",
    "    # DESCREVENDO ATRIBUTOS ESTATISTICOS DOS DADOS    \n",
    "    datadict,lista_atributo_geof,lista_atributo_geog,lista_atributo_proj,geof_df_describe = descricao(geof)\n",
    "\n",
    "    # ITERANDO ENTRE AS FOLHAS DE CARTAS\n",
    "    print(\"\")\n",
    "    print(f\"# --- Início da iteração entre as folhas cartográficas #\")\n",
    "\n",
    "    for index, row in malha_cartog_gdf_select.iterrows():\n",
    "        # RECORTANDO DATA PARA CADA FOLHA COM ['region.proj']\n",
    "        data = geof[vd.inside((geof.X, geof.Y), region = row.region_proj)]\n",
    "\n",
    "        # REMOVENDO VALORES NEGATIVOS DOS DADOS AEROGAMAESPECTOMETRICOS\n",
    "        data.loc[data.KPERC < 0, 'KPERC'] = 0\n",
    "        data.loc[data.eU < 0, 'eU'] = 0\n",
    "        data.loc[data.eTH < 0, 'eTH'] = 0\n",
    "\n",
    "        a,b,c,d,e = descricao(data)\n",
    "\n",
    "        # CALCULANDO RAZOES DE BANDAS PARA OS DADOS\n",
    "        lista_atributo_geof.append('U_TH')\n",
    "        lista_atributo_geof.append('U_K')\n",
    "        lista_atributo_geof.append('TH_K')\n",
    "\n",
    "\n",
    "        data_razoes = data\n",
    "\n",
    "        data_razoes.loc[data_razoes.eU < (e['eU']['mean']) / 10, 'eU'] = (e['eU']['mean']) / 10\n",
    "        data_razoes.loc[data_razoes.KPERC < (e['KPERC']['mean']) / 10, 'KPERC'] = (e['KPERC']['mean']) / 10\n",
    "        data_razoes.loc[data_razoes.eTH   < (e['eTH']['mean'])   / 10, 'eTH'] = (e['eTH']['mean']) / 10\n",
    "\n",
    "        data['U_TH'] = data_razoes.eU / data_razoes.eTH\n",
    "        data['U_K']  = data_razoes.eU  / data_razoes.KPERC\n",
    "        data['TH_K']  = data_razoes.eTH / data_razoes.KPERC\n",
    "\n",
    "\n",
    "        # GERANDO TUPLA DE COORDENADAS\n",
    "        if data.empty:\n",
    "            None\n",
    "            \n",
    "        elif len(data) < 1000:\n",
    "            None\n",
    "            #print(f\"A folha {index} possui apenas '{len(data)}' pontos coletados que devem ser adicionados a folha mais próxima\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"# Folha de código: {index}\")\n",
    "            print(f\" Atualizando dados brutos em dic_cartas['raw_data']\")\n",
    "            x = {index:data}\n",
    "            dic_cartas['raw_data'].update(x) \n",
    "            print(f\" com {len(data)} pontos de contagens radiométricas coletados com linhas de voo de {spacing} metros\")\n",
    "            \n",
    "            # ADICIONANDO ATRIBUTOS GEOFÍSICOS AO DICIONÁRIO INTERPOLADO\n",
    "            interpolado={}\n",
    "            for atributo in lista_atributo_geof:\n",
    "                x = {atributo:''}\n",
    "                interpolado.update(x)\n",
    "            #print(f\" Construindo dic_cartas['interpolado'] vazio com os atributos geofísicos\")\n",
    "            #print(interpolado.keys())\n",
    "                \n",
    "            # ADICIONANDO ATRIBUTOS AO DICIONÁRIO SCORES\n",
    "            scores={}\n",
    "            for atributo in lista_atributo_geof:\n",
    "                y = {atributo:''}\n",
    "                scores.update(y)\n",
    "\n",
    "            mean_score={}\n",
    "            for atributo in lista_atributo_geof:\n",
    "                x = {atributo:''}\n",
    "                mean_score.update(x)    \n",
    "\n",
    "            #print(f\" Construindo dicionário vazio de score do cross validation\")\n",
    "            #print(scores.keys())\n",
    "\n",
    "            # Iterando entre os canais de interpolação\n",
    "            print(\"\")\n",
    "            print(f\"# --- Inicio da interpolação com verde Splines # \")\n",
    "            for i in lista_atributo_geof:\n",
    "                # Definindo encadeamento de processsos para interpolação\n",
    "                chain = vd.Chain([\n",
    "                                ('trend', vd.Trend(degree=degree)),\n",
    "                                ('reduce', vd.BlockReduce(np.median, spacing=spacing)),\n",
    "                                ('spline', vd.Spline(dampings=dampings,\n",
    "                                                     mindist=mindist))\n",
    "                            ])\n",
    "                \n",
    "                print(f\"Encadeamento: {chain}\") \n",
    "                coordinates = (data.X.values, data.Y.values)\n",
    "                \n",
    "                # ESCOLHER MELHOR TRAIN TEST SPLIT\n",
    "\n",
    "\n",
    "                print(f\"Fitting Model of  '{i}' variable...\")\n",
    "                chain.fit(coordinates, data[i])\n",
    "\n",
    "                # Griding the predicted data.\n",
    "                print(f\"Predicting values of '{i}' to a regular grid of {psize} m\")\n",
    "                grid = chain.grid(spacing=psize, data_names=[i],pixel_register=True)\n",
    "                interpolado[i] = vd.distance_mask(coordinates, maxdist=1000, grid= grid)\n",
    "                \n",
    "                # ATUALIZAÇÃO DE DICIONÁRIO DE INTERPOLADOS\n",
    "                x = {index:interpolado}\n",
    "                dic_cartas['interpolado'].update(x)\n",
    "                print(f\" Dicionário de dados interpolados da folha {index} atualizados\")\n",
    "\n",
    "                # Processo de validação cruzada da biblioteca verde\n",
    "                if n_splits:\n",
    "                    cv     = vd.BlockKFold(spacing=spacing,\n",
    "                                n_splits=n_splits,\n",
    "                                shuffle=True)\n",
    "                    print(f\"Parâmetros de validação cruzada: {cv}\")\n",
    "\n",
    "                    scores[i] = vd.cross_val_score(chain,\n",
    "                                            coordinates,\n",
    "                                            data[i],\n",
    "                                            cv=cv,\n",
    "                                            delayed=True)\n",
    "\n",
    "                    import dask\n",
    "                    mean_score[i] = dask.delayed(np.mean)(scores[i])\n",
    "                    #print(\"Delayed mean:\", mean_score)\n",
    "\n",
    "                    mean_score[i] = mean_score[i].compute()\n",
    "                    print(\"Mean score:\", mean_score)\n",
    "\n",
    "\n",
    "                # ATUALIZAÇÃO DE DICIONÁRIO DE SCORES\n",
    "                #print(f\" Atualizando dicionário com scores\")\n",
    "                y = {index:scores}\n",
    "                dic_cartas['scores'].update(y)\n",
    "\n",
    "                x = {index:mean_score}\n",
    "                dic_cartas['mean_score'].update(x)\n",
    "                print(f\"# Folha {index} atualizada ao dicionário\")\n",
    "\n",
    "                \n",
    "                # SALVANDO DADOS INTERPOLADOS NO FORMATO .TIF\n",
    "                if save:\n",
    "                    local='grids/geof_'+str(save)+'_'+str(psize)+'m_'+i+'_'+row.id_folha+'.tif'\n",
    "                    print('salvando grids/geof_'+str(save)+'_'+str(psize)+'m_'+i+'_'+row.id_folha+'.tif')\n",
    "                    #grids[i].to_netcdf(gdb+'/grids/geof_3022_'+str(psize)+'m_'+i+'_'+row.id_folha+'.nc')\n",
    "                    tif_ = interpolado[i].rename(easting = 'x',northing='y')\n",
    "                    tif_.rio.to_raster(gdb+local)\n",
    "        \n",
    "            # RETIRANDO VALORES DE LITOLOGIA DE CADA PIXEL\n",
    "            if describe:\n",
    "                print(\"\")\n",
    "                print(f\"# --- Inicio da análise geoestatística\")\n",
    "                lista_interpolado = list()\n",
    "\n",
    "                for i in lista_atributo_geof:\n",
    "                    df = interpolado[i].to_dataframe()\n",
    "                    lista_interpolado.append(df[i])\n",
    "\n",
    "                geof_grids = pd.concat(lista_interpolado,axis=1, join='inner')\n",
    "                geof_grids.reset_index(inplace=True)\n",
    "                geof_grids['geometry'] =\\\n",
    "                     [geometry.Point(x,y) for x, y in zip(geof_grids['easting'], geof_grids['northing'])]\n",
    "\n",
    "                print('Ajustando crs')\n",
    "                if crs__=='proj':\n",
    "                    gdf = gpd.GeoDataFrame(geof_grids,crs=32723)\n",
    "                    gdf = gdf.set_crs(32723, allow_override=True)\n",
    "                    gdf = gdf.to_crs(\"EPSG:32723\")\n",
    "                    print(f\" geof: {gdf.crs}\")\n",
    "                else:\n",
    "                    gdf = gpd.GeoDataFrame(geof_grids,crs=32723)\n",
    "                    gdf = gdf.set_crs(32723, allow_override=True)\n",
    "                    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "                    print(f\" geof: {gdf.crs}\")\n",
    "\n",
    "                # IMPORTANDO VETORES LITOLÓGICOS\n",
    "                litologia = importar(camada,nome)\n",
    "                litologia.reset_index(inplace=True)\n",
    "                if crs__=='proj':\n",
    "                    litologia = litologia.set_crs(32723, allow_override=True)\n",
    "                    litologia = litologia.to_crs(\"EPSG:32723\")\n",
    "                    print(f\" lito: {litologia.crs}\")\n",
    "                else:\n",
    "                    litologia = litologia.set_crs(32723, allow_override=True)\n",
    "                    litologia = litologia.to_crs(\"EPSG:4326\")\n",
    "                    litologia=litologia.cx[row.region[0]:row.region[1],row.region[2]:row.region[3]]\n",
    "                    litologia.reset_index(inplace=True)\n",
    "                    print(f\" lito: {litologia.crs}\")\n",
    "\n",
    "\n",
    "                print(f\"# -- Calculando geometria mais próxima para cada um dos {len(geof_grids)} centróides de pixel\")\n",
    "                #print(f\"# Listagem de unidade geológicas do mapa litologia['MAPA'].unique():\")\n",
    "                #print(f\" {list(litologia['litologia'].unique())}\")\n",
    "                lito_geof = geof_grids\n",
    "                lito_geof['closest_unid'] = gdf['geometry'].apply(lambda x: litologia['litologia'].iloc[litologia.distance(x).idxmin()])\n",
    "                print(f\"# Listagem de unidades geológicas presentes na folha de id {index}:    \")\n",
    "                print(f\"  {list(lito_geof['closest_unid'].unique())}\")\n",
    "\n",
    "                # Adicionando lito_geof ao dicionario\n",
    "                print('')\n",
    "                print(f\" Adicionando dataframe com valores de litologia e geofíscios ao dicionário de cartas\")\n",
    "                x = {index:lito_geof}\n",
    "                dic_cartas['lito_geof'].update(x)\n",
    "                #print(dic_cartas['lito_geof'][index].keys())\n",
    "\n",
    "                print('__________________________________________')\n",
    "            print(\" \")\n",
    "    print(\"Dicionário de cartas disponível\")\n",
    "    return dic_cartas\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_region(escala,id,geof):\n",
    "    geof_dataframe = importar_geof(geof)\n",
    "    \n",
    "    # LISTANDO REGIOES DAS FOLHAS DE CARTAS\n",
    "    malha_cartog_gdf_select, dic_cartas = cartas(escala,id)\n",
    "        \n",
    "    # DESCREVENDO ATRIBUTOS ESTATISTICOS DOS DADOS    \n",
    "    datadict,lista_atributo_geof,lista_atributo_geog,lista_atributo_proj,geof_df_describe = descricao(geof_dataframe)\n",
    "\n",
    "    # ITERANDO ENTRE AS FOLHAS DE CARTAS\n",
    "    print(\"\")\n",
    "    print(f\"# --- Início da iteração entre as folhas cartográficas #\")\n",
    "\n",
    "    for index, row in malha_cartog_gdf_select.iterrows():\n",
    "        # RECORTANDO DATA PARA CADA FOLHA COM ['region.proj']\n",
    "        data = geof_dataframe[vd.inside((geof_dataframe.X, geof_dataframe.Y), region = row.region_proj)]\n",
    "        #del geof_dataframe\n",
    "        # GERANDO TUPLA DE COORDENADAS\n",
    "        if data.empty:\n",
    "            None\n",
    "            \n",
    "        elif len(data) < 1000:\n",
    "            None\n",
    "            #print(f\"A folha {index} possui apenas '{len(data)}' pontos coletados que devem ser adicionados a folha mais próxima\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"# Folha de código: {index}\")\n",
    "            print(f\" Atualizando dados brutos em dic_cartas['raw_data']\")\n",
    "            x = {index:data}\n",
    "            dic_cartas['raw_data'].update(x) \n",
    "            print(f\" com {len(data)} pontos\")\n",
    "            \n",
    "        \n",
    "    return dic_cartas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "dic_cartas = get_region('25k','SF23_Y_A_III_4_SE','mag_1105')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# --- Iniciando seleção de área de estudo\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ggrl/anaconda3/envs/geologist_bot/lib/python3.8/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['SF23_Y_A_III_4_SE'], dtype='object', name='id_folha')\n",
      "Gerando dicionário com o index\n",
      "dict_keys(['region', 'region_proj', 'raw_data', 'interpolado', 'scores', 'lito_geof', 'mean_score'])\n",
      "1 folha cartográfica selecionada\n",
      "\n",
      "# --- # Listagem de dados do aerolevantamento:  \n",
      "Lista de atributos geofísicos = ['ALTURA', 'MDT', 'ALTURA_1', 'MAGIGRF']\n",
      "lista de atributos geograficos = ['LATITUDE', 'LONGITUDE']\n",
      "lista de atributos projetados = ['X', 'Y']\n",
      "\n",
      "# --- Início da iteração entre as folhas cartográficas #\n",
      "# Folha de código: SF23_Y_A_III_4_SE\n",
      " Atualizando dados brutos em dic_cartas['raw_data']\n",
      " com 49331 pontos\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "data = dic_cartas['raw_data']['SF23_Y_A_III_4_SE']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALTURA</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>MDT</th>\n",
       "      <th>MAGIGRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672041</th>\n",
       "      <td>376.49</td>\n",
       "      <td>332876.04</td>\n",
       "      <td>7524887.92</td>\n",
       "      <td>781.03</td>\n",
       "      <td>49.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672042</th>\n",
       "      <td>378.10</td>\n",
       "      <td>332875.81</td>\n",
       "      <td>7524880.08</td>\n",
       "      <td>781.35</td>\n",
       "      <td>49.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672043</th>\n",
       "      <td>378.76</td>\n",
       "      <td>332875.58</td>\n",
       "      <td>7524872.25</td>\n",
       "      <td>781.65</td>\n",
       "      <td>49.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672044</th>\n",
       "      <td>378.37</td>\n",
       "      <td>332875.35</td>\n",
       "      <td>7524864.42</td>\n",
       "      <td>781.92</td>\n",
       "      <td>49.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672045</th>\n",
       "      <td>377.60</td>\n",
       "      <td>332875.12</td>\n",
       "      <td>7524856.57</td>\n",
       "      <td>782.05</td>\n",
       "      <td>49.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085077</th>\n",
       "      <td>115.43</td>\n",
       "      <td>345674.28</td>\n",
       "      <td>7515612.00</td>\n",
       "      <td>824.09</td>\n",
       "      <td>95.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085078</th>\n",
       "      <td>117.38</td>\n",
       "      <td>345681.35</td>\n",
       "      <td>7515611.83</td>\n",
       "      <td>823.98</td>\n",
       "      <td>95.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085079</th>\n",
       "      <td>119.37</td>\n",
       "      <td>345688.42</td>\n",
       "      <td>7515611.67</td>\n",
       "      <td>823.97</td>\n",
       "      <td>96.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085080</th>\n",
       "      <td>121.40</td>\n",
       "      <td>345695.48</td>\n",
       "      <td>7515611.50</td>\n",
       "      <td>824.05</td>\n",
       "      <td>96.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085081</th>\n",
       "      <td>123.46</td>\n",
       "      <td>345702.55</td>\n",
       "      <td>7515611.34</td>\n",
       "      <td>824.22</td>\n",
       "      <td>96.342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49331 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ALTURA          X           Y     MDT  MAGIGRF\n",
       "672041    376.49  332876.04  7524887.92  781.03   49.578\n",
       "672042    378.10  332875.81  7524880.08  781.35   49.661\n",
       "672043    378.76  332875.58  7524872.25  781.65   49.738\n",
       "672044    378.37  332875.35  7524864.42  781.92   49.811\n",
       "672045    377.60  332875.12  7524856.57  782.05   49.886\n",
       "...          ...        ...         ...     ...      ...\n",
       "12085077  115.43  345674.28  7515612.00  824.09   95.717\n",
       "12085078  117.38  345681.35  7515611.83  823.98   95.870\n",
       "12085079  119.37  345688.42  7515611.67  823.97   96.026\n",
       "12085080  121.40  345695.48  7515611.50  824.05   96.183\n",
       "12085081  123.46  345702.55  7515611.34  824.22   96.342\n",
       "\n",
       "[49331 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "data.drop(columns=['MDT'],inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "plt.figure()\n",
    "tmp = plt.scatter(data.LONGITUDE, data.LATITUDE, c=data.MAGIGRF, s=1)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.colorbar(tmp, label=\"mGal\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c0a8a71140b4dc5bd8dac36df842c3a"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'LONGITUDE'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4933/3945677718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLONGITUDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLATITUDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIGRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"equal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mGal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geologist_bot/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'LONGITUDE'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "plt.figure()\n",
    "tmp = plt.scatter(data.X, data.Y, c=data.MAGIGRF, s=1)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.colorbar(tmp, label=\"nT\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1c82666b1404170aed1e87539cfb68f"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "plt.figure()\n",
    "tmp = plt.scatter(data.X, data.Y, c=data.MDT, s=1)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.colorbar(tmp, label=\"m\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd3d9c4bf0864400bfed53549b24d716"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(\"Number of data points:\", data.shape[0])\n",
    "print(\"Mean height of observations:\", data.ALTURA.mean())\n",
    "print(\"Mean height of observations:\", data.ALTURA_1.mean())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of data points: 49331\n",
      "Mean height of observations: 183.26372787902017\n",
      "Mean height of observations: 176.38948146195952\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "coordinates = (data.X, data.Y, data.ALTURA)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "eql = hm.EQLHarmonic(relative_depth=1000, damping=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "eql.fit(coordinates, data.MAGIGRF)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "print(\"R² score:\", eql.score(coordinates, data.MAGIGRF))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'eql' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3635/1116328709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R² score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIGRF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eql' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid = eql.grid(upward=1500, spacing=100, data_names=[\"magnetic_anomaly\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"\\nGenerated grid:\\n\", grid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 9), sharey=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "maxabs = vd.maxabs(data.MAGIGRF, grid.magnetic_anomaly.values)\n",
    "\n",
    "ax1.set_title(\"Observed magnetic anomaly data\")\n",
    "tmp = ax1.scatter(\n",
    "    data.X,\n",
    "    data.Y,\n",
    "    c=data.MAGIGRF,\n",
    "    s=20,\n",
    "    vmin=-maxabs,\n",
    "    vmax=maxabs,\n",
    "    cmap=\"seismic\",\n",
    ")\n",
    "plt.colorbar(tmp, ax=ax1, label=\"nT\", pad=0.05, aspect=40, orientation=\"horizontal\")\n",
    "ax1.set_xlim(data.X.min(), data.X.max())\n",
    "ax1.set_ylim(data.Y.min(), data.Y.max())\n",
    "\n",
    "ax2.set_title(\"Gridded and upward-continued\")\n",
    "tmp = grid.magnetic_anomaly.plot.pcolormesh(\n",
    "    ax=ax2,\n",
    "    add_colorbar=False,\n",
    "    add_labels=False,\n",
    "    vmin=-maxabs,\n",
    "    vmax=maxabs,\n",
    "    cmap=\"seismic\",\n",
    ")\n",
    "plt.colorbar(tmp, ax=ax2, label=\"nT\", pad=0.05, aspect=40, orientation=\"horizontal\")\n",
    "ax2.set_xlim(data.X.min(), data.X.max())\n",
    "ax2.set_ylim(data.Y.min(), data.Y.max())\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('geologist_bot': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "044c3e0300da4fa3c2a1f13c93c64a53d39114a9c33e72628e43c9ffd211a0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}